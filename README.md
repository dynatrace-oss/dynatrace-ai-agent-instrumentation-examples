# Dynatrace Agentic AI instrumentation examples

This project demonstrates how to integrate Dynatrace with AI agents to achieve robust observability for Agentic AI loads, performance and cost monitoring, and get actionable insights. 
By instrumenting AI agents with Dynatrace, you gain the ability to monitor their behavior, tool usage, track dependencies, and ensure optimal performance across complex environments.

Key Features:
- *End-to-End Observability*: Monitor AI agent interactions, tool usage dependencies, performance, cost metrics, and token consumption. 
- *Tracing and debugging*: Trace agent execution, tool usage, prompt flows from initial request to final response for quick root cause analysis and troubleshooting. 
- *Actionable Insights*: Leverage Dynatrace's AI-powered analytics to identify bottlenecks, optimize resource utilization, and troubleshoot issues.
- *Seamless Integration*: Learn how to embed Dynatrace instrumentation into AI agents in matter of minutes.

![Tracing](/mcp/dynatrace.png)

This repository is perfect for developers, DevOps engineers, and AI practitioners looking to enhance the reliability and scalability of their Agentic AI applications and service.
Whether you're building chatbots, recommendation engines, or autonomous systems, this guide will help you unlock the full potential of Dynatrace AI and Agent Observability.

## Supported Frameworks
This repository includes examples and guidance for integrating Dynatrace with the following AI Agent building frameworks and libraries:

- [Google Agent Development Kit (ADK)](./google-adk-sample/)
- [AWS Strands Agents](./aws-agent-sample/)
- [OpenAI Agents SDK](./openai-agent-sample/)
- [MCP - Model Context Protocol](./mcp/)

![MCP Agentic AI](/mcp/architecture.png)


If you’re using a framework that isn’t listed here, don’t worry! [You can explore the Dynatrace Hub for the full list of supported technologies.](https://www.dynatrace.com/hub/?filter=ai-ml-observability&internal_source=doc&internal_medium=link&internal_campaign=cross)
